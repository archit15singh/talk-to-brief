# Audio Brief Generator

A complete pipeline for converting audio files into structured, actionable briefs using AI analysis.

## Features

- **Audio Transcription**: Fast transcription with timestamps using faster-whisper (base model)
- **Intelligent Chunking**: Smart segmentation respecting sentence boundaries (~1200 words)
- **Parallel Analysis**: Concurrent GPT-4 processing for optimal performance
- **Structured Output**: Organized briefs with conversation starters, strategic questions, and key insights

## Project Structure

```
â”œâ”€â”€ pipeline.py              # Main orchestrator script
â”œâ”€â”€ src/                     # Core pipeline components
â”‚   â”œâ”€â”€ transcribe.py        # Audio â†’ timestamped transcript
â”‚   â”œâ”€â”€ analyze_chunk.py     # Transcript â†’ parallel GPT-4 analysis
â”‚   â””â”€â”€ merge_brief.py       # Partials â†’ final brief
â”œâ”€â”€ config/                  # Configuration and prompts
â”‚   â””â”€â”€ per_chunk.md         # GPT-4 analysis prompt template
â”œâ”€â”€ data/                    # All data artifacts
â”‚   â”œâ”€â”€ audio/               # Input audio files
â”‚   â”œâ”€â”€ transcripts/         # Generated transcripts
â”‚   â”œâ”€â”€ partials/            # Individual chunk analyses
â”‚   â””â”€â”€ outputs/             # Final briefs
â””â”€â”€ requirements.txt         # Python dependencies
```

## Installation

1. Clone the repository
2. Create virtual environment:
```bash
python3 -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Set up your OpenAI API key:
   - Create a `.env` file in the project root
   - Add your OpenAI API key:
   ```
   OPENAI_API_KEY=your-api-key-here
   ```
   - **Important**: Ensure you have GPT-4 access on your OpenAI account
   - **Security**: Never commit the `.env` file to version control

5. Validate your setup:
```bash
python validate_setup.py
```

## Usage

### Complete Pipeline (Recommended)

Process an audio file from start to finish:

```bash
python pipeline.py data/audio/your_file.mp3
```

With custom output name:
```bash
python pipeline.py data/audio/your_file.mp3 --output-name "my_talk"
```

### Individual Steps

Run specific pipeline steps:

```bash
# Step 1: Transcription only
python pipeline.py data/audio/your_file.mp3 --step transcribe

# Step 2: Analysis only (requires existing transcript)
python pipeline.py data/audio/your_file.mp3 --step analyze

# Step 3: Brief generation only (requires existing partials)
python pipeline.py data/audio/your_file.mp3 --step merge
```

### Direct Script Usage

You can also run individual scripts directly:

```bash
# Transcribe audio
python src/transcribe.py data/audio/your_file.mp3 data/transcripts/output.txt

# Analyze transcript
python src/analyze_chunk.py data/transcripts/input.txt data/partials/output_dir

# Generate brief
python src/merge_brief.py data/partials/input_dir data/outputs/brief.md
```

## Example Run Logs

Here's what a typical pipeline execution looks like:

### Complete Pipeline Run

```bash
$ python pipeline.py data/audio/sample.mp3
ğŸµ Starting Audio Brief Generator Pipeline
ğŸ“ Processing: data/audio/sample.mp3
ğŸ“ Output name: sample

=== STEP 1: TRANSCRIPTION ===
ğŸ¤ Transcribing audio with faster-whisper...
â±ï¸  Audio duration: 45:32
ğŸ“„ Transcript saved: data/transcripts/sample_transcript.txt
âœ… Transcription complete (2.3 minutes)

=== STEP 2: ANALYSIS ===
ğŸ“Š Analyzing transcript in chunks...
ğŸ”„ Created 8 chunks (~1200 words each)
ğŸš€ Starting parallel analysis with 4 workers...
  âœ“ Chunk 1/8 complete (12.4s)
  âœ“ Chunk 2/8 complete (15.1s)
  âœ“ Chunk 3/8 complete (11.8s)
  âœ“ Chunk 4/8 complete (13.7s)
  âœ“ Chunk 5/8 complete (14.2s)
  âœ“ Chunk 6/8 complete (12.9s)
  âœ“ Chunk 7/8 complete (16.3s)
  âœ“ Chunk 8/8 complete (10.8s)
ğŸ’¾ Analysis saved: data/partials/sample/
âœ… Analysis complete (3.1 minutes)

=== STEP 3: BRIEF GENERATION ===
ğŸ“‹ Merging 8 partial analyses...
ğŸ”— Combining insights and removing duplicates...
ğŸ“ Generating final brief structure...
ğŸ’¾ Brief saved: data/outputs/sample_brief.md
âœ… Brief generation complete (0.2 minutes)

ğŸ‰ Pipeline complete! Total time: 5.6 minutes
ğŸ“„ Final brief: data/outputs/sample_brief.md
```

### Individual Step Examples

**Transcription only:**
```bash
$ python pipeline.py data/audio/sample.mp3 --step transcribe
ğŸµ Starting Audio Brief Generator Pipeline
ğŸ“ Processing: data/audio/sample.mp3
ğŸ“ Output name: sample

=== STEP 1: TRANSCRIPTION ===
ğŸ¤ Transcribing audio with faster-whisper...
â±ï¸  Audio duration: 45:32
ğŸ“„ Transcript saved: data/transcripts/sample_transcript.txt
âœ… Transcription complete (2.3 minutes)

âœ¨ Transcription step complete!
```

**Analysis with existing transcript:**
```bash
$ python pipeline.py data/audio/sample.mp3 --step analyze
ğŸµ Starting Audio Brief Generator Pipeline
ğŸ“ Processing: data/audio/sample.mp3
ğŸ“ Output name: sample

=== STEP 2: ANALYSIS ===
ğŸ“Š Found existing transcript: data/transcripts/sample_transcript.txt
ğŸ”„ Created 8 chunks (~1200 words each)
ğŸš€ Starting parallel analysis with 4 workers...
  âœ“ All chunks processed successfully
ğŸ’¾ Analysis saved: data/partials/sample/
âœ… Analysis complete (3.1 minutes)

âœ¨ Analysis step complete!
```

**Error handling example:**
```bash
$ python pipeline.py data/audio/nonexistent.mp3
ğŸµ Starting Audio Brief Generator Pipeline
ğŸ“ Processing: data/audio/nonexistent.mp3
âŒ Error: Audio file not found: data/audio/nonexistent.mp3
ğŸ’¡ Tip: Check the file path and ensure the audio file exists
```

## Output Structure

For an audio file named `sample.mp3`, the pipeline generates:

```
data/
â”œâ”€â”€ transcripts/sample_transcript.txt    # Timestamped transcript
â”œâ”€â”€ partials/sample/                     # Individual analyses
â”‚   â”œâ”€â”€ chunk_00.json
â”‚   â”œâ”€â”€ chunk_01.json
â”‚   â””â”€â”€ ...
â””â”€â”€ outputs/sample_brief.md              # Final structured brief
```

## Brief Format

The generated brief includes:

1. **Executive Summary** - Overview of content and insights
2. **Approach Scripts** - Conversation starters with specific timestamps
3. **Strategic Questions** - High-signal, outcome-oriented questions
4. **Timeline Highlights** - Chronological key moments
5. **Claims, Assumptions & Trade-offs** - Critical decision points

## Configuration

### Analysis Prompt

Customize the GPT-4 analysis by editing `config/per_chunk.md`. The prompt controls:
- Output format and structure
- Analysis depth and focus
- Word count limits
- Specific instructions for each section

### Pipeline Parameters

Key parameters can be adjusted in the source files:
- **Chunk size**: Modify `target_words` in `analyze_chunk.py` (default: 1200)
- **Parallel workers**: Adjust `max_workers` in `analyze_chunk.py` (default: 4)
- **GPT-4 model**: Change model in `analyze_chunk.py` (default: "gpt-4")

## Requirements

- Python 3.8+
- OpenAI API key with GPT-4 access
- Audio files in supported formats: WAV, MP3, M4A, MP4, FLAC, OGG
- Sufficient disk space for transcripts and analysis files

## Troubleshooting

### Common Issues

1. **Missing API Key**: Ensure `OPENAI_API_KEY` is set in your environment
2. **Audio Format**: Verify your audio file is in a supported format
3. **Memory Issues**: For very long audio files, consider splitting them first
4. **Network Timeouts**: Check internet connection for GPT-4 API calls

### Performance Tips

- Use shorter audio files (< 2 hours) for optimal performance
- Ensure stable internet connection for API calls
- Monitor API usage and rate limits
- Use SSD storage for faster I/O operations

## License

MIT License - see LICENSE file for details.